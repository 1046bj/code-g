from duckduckgo_search import DDGS
import re
from datetime import datetime
import asyncio
import random

# --- [ë¹„ìƒìš©] ì„œë²„ ì°¨ë‹¨ ì‹œ ë³´ì—¬ì¤„ ë°ì´í„° ---
FALLBACK_DATA = [
    {"title": "[ì„œë²„ì°¨ë‹¨ë¨] K-Startup ì˜ˆë¹„ì°½ì—…íŒ¨í‚¤ì§€ (ì˜ˆì‹œ)", "agency": "K-Startup", "date": "2025-01-30", "deadline": "2025-02-28", "d_day": "D-29", "link": "https://www.k-startup.go.kr", "match_score": 99, "summary": "í˜„ì¬ ë¬´ë£Œ ì„œë²„ IPê°€ ê²€ìƒ‰ ì—”ì§„ì— ì˜í•´ ì¼ì‹œ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” ì˜ˆì‹œ ë°ì´í„°ì…ë‹ˆë‹¤."},
    {"title": "[ì„œë²„ì°¨ë‹¨ë¨] AI ë°”ìš°ì²˜ ì§€ì›ì‚¬ì—… (ì˜ˆì‹œ)", "agency": "NIPA", "date": "2025-01-15", "deadline": "2025-03-15", "d_day": "D-45", "link": "https://www.nipa.kr", "match_score": 95, "summary": "ì„œë²„ íŠ¸ë˜í”½ ê³¼ë¶€í•˜ë¡œ ì¸í•´ ì‹¤ì‹œê°„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."},
    {"title": "[ì„œë²„ì°¨ë‹¨ë¨] ìŠ¤ë§ˆíŠ¸íŒœ ICT ê¸°ìì¬ ë³´ê¸‰ì‚¬ì—…", "agency": "ë†ë¦¼ì¶•ì‚°ì‹í’ˆë¶€", "date": "2025-02-01", "deadline": "2025-04-01", "d_day": "D-60", "link": "https://www.mafra.go.kr", "match_score": 88, "summary": "ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì‹œê±°ë‚˜ ë¡œì»¬ í™˜ê²½ì—ì„œ í…ŒìŠ¤íŠ¸í•´ì£¼ì„¸ìš”."},
]

def generate_search_queries(profile):
    current_year = datetime.now().year
    queries = []
    
    # ê²€ìƒ‰ ì¿¼ë¦¬ ê°„ì†Œí™” (ì°¨ë‹¨ í™•ë¥  ë‚®ì¶”ê¸° ìœ„í•¨)
    for ind in profile.industry:
        clean_ind = ind.split('(')[0]
        # site: ì œí•œì„ í’€ê³  ê²€ìƒ‰ (ì°¨ë‹¨ ìš°íšŒ ì‹œë„)
        queries.append(f'{clean_ind} ì •ë¶€ ì§€ì›ì‚¬ì—… ê³µê³  {current_year}')
    
    return queries[:2] # ì¿¼ë¦¬ ìˆ˜ ì¤„ì„

def extract_date(text):
    match = re.search(r'202\d[-.](0[1-9]|1[0-2])[-.](0[1-9]|[12]\d|3[01])', text)
    if match: return match.group(0)
    return None

async def search_duckduckgo(query):
    results = []
    print(f"ğŸ•µï¸ [Search] ê²€ìƒ‰ ì‹œë„: {query}")
    
    try:
        # Proxyë‚˜ User-Agent ì„¤ì •ì´ ì—†ìœ¼ë©´ ì„œë²„ì—ì„œ ë§‰í í™•ë¥  ë†’ìŒ
        # DDGS ë¼ì´ë¸ŒëŸ¬ë¦¬ ë‚´ë¶€ì ìœ¼ë¡œ ì²˜ë¦¬ë¥¼ ì‹œë„í•¨
        with DDGS() as ddgs:
            ddg_results = list(ddgs.text(query, region='kr-kr', timelimit='m', max_results=3))
            
        for r in ddg_results:
            body = r.get('body', '')
            found_date = extract_date(body)
            
            results.append({
                "title": r.get('title', ''),
                "agency": "ì›¹ê²€ìƒ‰", 
                "date": datetime.now().strftime("%Y-%m-%d"),
                "deadline": found_date if found_date else "ìƒì„¸ë³´ê¸°",
                "d_day": "D-??",
                "link": r.get('href', ''),
                "match_score": random.randint(80, 99),
                "summary": body
            })
            
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì°¨ë‹¨/ì˜¤ë¥˜ ë°œìƒ: {e}")
        # ì—¬ê¸°ì„œ ì—ëŸ¬ê°€ ë‚˜ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ -> ì•„ë˜ get_noticesì—ì„œ ë¹„ìƒ ë°ì´í„° ì‚¬ìš©
        
    return results

async def get_notices(profile):
    queries = generate_search_queries(profile)
    all_results = []
    
    # 1. ì‹¤ì œ ê²€ìƒ‰ ì‹œë„
    for q in queries:
        res = await search_duckduckgo(q)
        all_results.extend(res)
        
    # 2. [í•µì‹¬] ê²°ê³¼ê°€ 0ê°œë©´(ì°¨ë‹¨ë‹¹í–ˆìœ¼ë©´) ë¹„ìƒ ë°ì´í„° ë°˜í™˜
    if len(all_results) == 0:
        print("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ 0ê±´ (IP ì°¨ë‹¨ ì˜ì‹¬). ë¹„ìƒìš© ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
        return FALLBACK_DATA

    # ì¤‘ë³µ ì œê±°
    unique_results = {v['link']: v for v in all_results}.values()
    return list(unique_results)