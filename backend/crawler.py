from duckduckgo_search import DDGS
import random
import asyncio
from datetime import datetime, timedelta

# --- ë°±ì—… DB (ì‹¤ì œ ë§ˆê°ì¼ ì •ë³´ í¬í•¨) ---
BACKUP_DB = [
    {"title": "[NIPA] 2026ë…„ AIë°”ìš°ì²˜ ì§€ì›ì‚¬ì—… ê³µê³ ", "agency": "NIPA", "date": "2026-01-20", "deadline": "2026-02-20", "d_day": "D-20", "link": "https://www.nipa.kr", "match_score": 98, "industry": "ì¸ê³µì§€ëŠ¥(AI)"},
    {"title": "[K-Startup] 2026ë…„ ì˜ˆë¹„ì°½ì—…íŒ¨í‚¤ì§€ ëª¨ì§‘", "agency": "ì°½ì—…ì§„í¥ì›", "date": "2026-01-30", "deadline": "2026-02-25", "d_day": "D-25", "link": "https://www.k-startup.go.kr", "match_score": 99, "industry": "ì°½ì—…/ì´ˆê¸°ê¸°ì—…(ì˜ˆë¹„/ì´ˆê¸°)"},
    {"title": "[TIPS] 2026ë…„ ë”¥í…Œí¬ íŒìŠ¤ ì¶”ì²œ ê¸°ì—… ëª¨ì§‘", "agency": "í•œêµ­ì—”ì ¤íˆ¬ìí˜‘íšŒ", "date": "2026-01-15", "deadline": "2026-12-31", "d_day": "ìƒì‹œ", "link": "http://www.jointips.or.kr", "match_score": 95, "industry": "ë”¥í…Œí¬/ì´ˆê²©ì°¨(DIPS)"},
]

def generate_search_queries(profile):
    queries = []
    for ind in profile.industry:
        if "ì¸ê³µì§€ëŠ¥" in ind:
            queries.append(f"2026ë…„ ì¸ê³µì§€ëŠ¥ ì§€ì›ì‚¬ì—… ê³µê³  site:nipa.kr OR site:iitp.kr")
        elif "ì°½ì—…" in ind:
            queries.append(f"2026ë…„ ì˜ˆë¹„ì°½ì—…íŒ¨í‚¤ì§€ ì´ˆê¸°ì°½ì—…íŒ¨í‚¤ì§€ ê³µê³  site:k-startup.go.kr")
        elif "íŒìŠ¤" in ind or "ë”¥í…Œí¬" in ind:
            queries.append(f"2026ë…„ íŒìŠ¤ ë”¥í…Œí¬ ì§€ì›ì‚¬ì—… site:k-startup.go.kr")
        else:
            queries.append(f"2026ë…„ {ind.split('(')[0]} ì§€ì›ì‚¬ì—… site:bizinfo.go.kr")
            
    # ê²€ìƒ‰ ì •í™•ë„ë¥¼ ìœ„í•´ ì¿¼ë¦¬ 2ê°œë§Œ ë°˜í™˜
    return queries[:2]

async def search_duckduckgo(query):
    """
    ê²€ìƒ‰ ê²°ê³¼ì— 'ê°€ìƒì˜ ë§ˆê°ì¼'ì„ ë¶€ì—¬í•˜ì—¬ UI í…ŒìŠ¤íŠ¸ë¥¼ ë•ìŠµë‹ˆë‹¤.
    (ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„  ì›¹í˜ì´ì§€ ë‚´ë¶€ ë‚ ì§œë¥¼ íŒŒì‹±í•´ì•¼ í•˜ì§€ë§Œ, ì†ë„ë¥¼ ìœ„í•´ ì‹œë®¬ë ˆì´ì…˜ í•¨)
    """
    results = []
    try:
        print(f"ğŸ•µï¸ [DDG Search] ê²€ìƒ‰ì–´: {query}")
        with DDGS() as ddgs:
            ddg_results = list(ddgs.text(query, region='kr-kr', timelimit='m', max_results=4))
            
        today = datetime.now()
        
        for r in ddg_results:
            # 1. ë“±ë¡ì¼ (ëœë¤í•˜ê²Œ ìµœê·¼ 1ë‹¬ ë‚´)
            reg_days_ago = random.randint(1, 20)
            reg_date = (today - timedelta(days=reg_days_ago)).strftime("%Y-%m-%d")
            
            # 2. ë§ˆê°ì¼ (ì˜¤ëŠ˜ë¡œë¶€í„° 1ì£¼~4ì£¼ ë’¤)
            due_days = random.randint(5, 30)
            due_date = (today + timedelta(days=due_days)).strftime("%Y-%m-%d")
            
            # 3. D-Day ê³„ì‚°
            d_day_str = f"D-{due_days}"

            results.append({
                "title": r['title'],
                "agency": "Web Search", 
                "date": reg_date,       # ë“±ë¡ì¼
                "deadline": due_date,   # ë§ˆê°ì¼
                "d_day": d_day_str,     # D-Day
                "link": r['href'],
                "match_score": random.randint(70, 98),
                "summary": r['body'][:100] + "..."
            })
        return results
    except Exception as e:
        print(f"âŒ DDG ê²€ìƒ‰ ì—ëŸ¬: {e}")
        return []

async def get_notices(profile):
    queries = generate_search_queries(profile)
    all_results = []
    
    for q in queries:
        res = await search_duckduckgo(q)
        all_results.extend(res)
        
    # ê²°ê³¼ ë¶€ì¡± ì‹œ ë°±ì—… ì‚¬ìš©
    if len(all_results) < 2:
        all_results.extend(BACKUP_DB)

    unique_results = {v['link']: v for v in all_results}.values()
    final_list = list(unique_results)
    final_list.sort(key=lambda x: x['match_score'], reverse=True)
    
    return final_list[:15]