from duckduckgo_search import DDGS
import re
from datetime import datetime
import asyncio

# --- [ì„¤ì •] ëŒ€í•œë¯¼êµ­ í•µì‹¬ ì •ë¶€ì§€ì›/ê³µê³  ì‚¬ì´íŠ¸ ë¦¬ìŠ¤íŠ¸ (15ê³³) ---
TARGET_SITES_MAP = {
    "k-startup.go.kr": "K-Startup",
    "bizinfo.go.kr": "ê¸°ì—…ë§ˆë‹¹",
    "g2b.go.kr": "ë‚˜ë¼ì¥í„°", 
    "kvic.or.kr": "í•œêµ­ë²¤ì²˜íˆ¬ì",
    "smtech.go.kr": "SMTech",
    "nrf.re.kr": "í•œêµ­ì—°êµ¬ì¬ë‹¨",
    "iris.go.kr": "IRIS",
    "nipa.kr": "NIPA",
    "iitp.kr": "IITP",
    "keit.re.kr": "KEIT",
    "kocca.kr": "ì½˜í…ì¸ ì§„í¥ì›",
    "khidi.or.kr": "ë³´ê±´ì‚°ì—…ì§„í¥ì›",
    "nia.or.kr": "NIA",
    "tp.or.kr": "í…Œí¬ë…¸íŒŒí¬",
    "venture.or.kr": "ë²¤ì²˜ê¸°ì—…í˜‘íšŒ"
}

def generate_search_queries(profile):
    current_year = datetime.now().year
    queries = []
    
    # --- 1ì°¨: í•µì‹¬ ì‚¬ì´íŠ¸ ê·¸ë£¹í•‘ ê²€ìƒ‰ ---
    # ê·¸ë£¹ì„ ë„ˆë¬´ ì˜ê²Œ ìª¼ê°œì§€ ë§ê³ , ê°€ì¥ ì¤‘ìš”í•œ 'ì¢…í•©'ê³¼ 'ê¸°ìˆ 'ë¡œë§Œ ë‚˜ëˆ•ë‹ˆë‹¤.
    
    sites_biz = [
        "site:k-startup.go.kr", "site:bizinfo.go.kr", "site:g2b.go.kr", 
        "site:smtech.go.kr", "site:nipa.kr", "site:nrf.re.kr"
    ]
    # ì¿¼ë¦¬ ê¸¸ì´ ì œí•œì„ í”¼í•˜ê¸° ìœ„í•´ í•µì‹¬ 6ê³³ë§Œ ìš°ì„  íƒ€ê²ŸíŒ…
    query_sites = "(" + " OR ".join(sites_biz) + ")"

    for ind in profile.industry:
        clean_ind = ind.split('(')[0]
        # ë”°ì˜´í‘œ("")ë¥¼ ì œê±°í•˜ì—¬ ê²€ìƒ‰ ìœ ì—°ì„± í™•ë³´ (ex: "ì¸ê³µì§€ëŠ¥" -> ì¸ê³µì§€ëŠ¥)
        queries.append(f'{query_sites} {clean_ind} ì§€ì›ì‚¬ì—… ê³µê³  {current_year}')

    # ëª©ì ë³„ ê²€ìƒ‰
    if "ì‚¬ì—…í™”" in profile.goal:
        queries.append(f'site:k-startup.go.kr ì˜ˆë¹„ì°½ì—…íŒ¨í‚¤ì§€ ì´ˆê¸°ì°½ì—…íŒ¨í‚¤ì§€ {current_year}')
    
    return queries[:3]

def get_fallback_queries(profile):
    """
    [ë¹„ìƒìš©] 1ì°¨ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ë•Œ ì‚¬ìš©í•  'ê´‘ì—­ ê²€ìƒ‰' ì¿¼ë¦¬
    íŠ¹ì • ì‚¬ì´íŠ¸ ì œí•œì„ í’€ë˜, ìœ„í‚¤/ë¸”ë¡œê·¸ ë“± ë…¸ì´ì¦ˆë¥¼ ì œì™¸í•¨
    """
    current_year = datetime.now().year
    queries = []
    
    # ì œì™¸ì–´ ì„¤ì • (ìœ„í‚¤, ë‚˜ë¬´ìœ„í‚¤, ë¸”ë¡œê·¸ ë“±)
    exclude = "-site:wikipedia.org -site:namu.wiki -site:tistory.com -site:blog.naver.com"
    
    for ind in profile.industry:
        clean_ind = ind.split('(')[0]
        # ì‚¬ì´íŠ¸ ì œí•œ ì—†ì´ 'ì •ë¶€ì§€ì›' í‚¤ì›Œë“œë¡œ ê²€ìƒ‰
        queries.append(f'{clean_ind} ì •ë¶€ ì§€ì›ì‚¬ì—… ê³µê³  {current_year} {exclude}')
        
    return queries[:2]

def extract_date(text):
    match = re.search(r'202\d[-.](0[1-9]|1[0-2])[-.](0[1-9]|[12]\d|3[01])', text)
    if match: return match.group(0)
    return None

def detect_agency(link):
    for domain, name in TARGET_SITES_MAP.items():
        if domain in link: return name
    return "ì •ë¶€ê³µê³ " # ì‚¬ì´íŠ¸ ë¦¬ìŠ¤íŠ¸ì— ì—†ìœ¼ë©´ ì¼ë°˜ ì •ë¶€ê³µê³ ë¡œ í‘œì‹œ

async def search_duckduckgo(query, is_fallback=False):
    results = []
    print(f"ğŸ•µï¸ [{'Fallback' if is_fallback else 'Target'}-Search] ê²€ìƒ‰ì–´: {query}")
    
    try:
        with DDGS() as ddgs:
            # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ë°”ë¡œ ë¦¬í„´
            ddg_results = list(ddgs.text(query, region='kr-kr', timelimit='m', max_results=5))
            
        for r in ddg_results:
            link = r.get('href', '')
            agency = detect_agency(link)
            found_date = extract_date(r.get('body', ''))
            
            # Fallback ëª¨ë“œì¼ ë•Œ, ë„ˆë¬´ ì—‰ëš±í•œ ì‚¬ì´íŠ¸(ì‡¼í•‘ëª° ë“±)ê°€ ê±¸ë¦´ ìˆ˜ ìˆìœ¼ë¯€ë¡œ 
            # ì œëª©ì— 'ê³µê³ 'ë‚˜ 'ëª¨ì§‘'ì´ ì—†ìœ¼ë©´ ê±°ë¥´ëŠ” í•„í„°ë¥¼ ì¶”ê°€í•  ìˆ˜ë„ ìˆìŒ.
            
            results.append({
                "title": r.get('title', '').split(" - ")[0], 
                "agency": agency, 
                "date": datetime.now().strftime("%Y-%m-%d"),
                "deadline": found_date if found_date else "ê³µê³ ë¬¸ ì°¸ì¡°",
                "d_day": "D-??",
                "link": link,
                "match_score": 70 if is_fallback else 90, # Fallback ê²°ê³¼ëŠ” ì ìˆ˜ë¥¼ ì¢€ ë‚®ê²Œ ì¤Œ
                "summary": r.get('body', '')
            })
            
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
    return results

async def get_notices(profile):
    # 1. ì •ë°€ íƒ€ê²ŸíŒ… ê²€ìƒ‰ ì‹¤í–‰
    queries = generate_search_queries(profile)
    all_results = []
    
    for q in queries:
        res = await search_duckduckgo(q, is_fallback=False)
        all_results.extend(res)
        
    # 2. [ì•ˆì „ì¥ì¹˜] ë§Œì•½ ê²°ê³¼ê°€ ë„ˆë¬´ ì ìœ¼ë©´(2ê°œ ë¯¸ë§Œ), ê´‘ì—­ ê²€ìƒ‰(Fallback) ì‹¤í–‰
    if len(all_results) < 2:
        print("âš ï¸ ê²°ê³¼ ë¶€ì¡±! ì•ˆì „ì¥ì¹˜(Fallback) ê²€ìƒ‰ì„ ê°€ë™í•©ë‹ˆë‹¤.")
        fallback_queries = get_fallback_queries(profile)
        for q in fallback_queries:
            res = await search_duckduckgo(q, is_fallback=True)
            all_results.extend(res)

    # ì¤‘ë³µ ì œê±°
    unique_results = {v['link']: v for v in all_results}.values()
    final_list = list(unique_results)
    
    # ê²°ê³¼ê°€ ìˆì–´ë„ ì—ëŸ¬ê°€ ì•ˆ ë‚˜ê²Œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¼ë„ ë°˜í™˜
    return final_list