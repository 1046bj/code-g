from duckduckgo_search import DDGS
import re
from datetime import datetime
import asyncio

# --- [ì„¤ì •] ëŒ€í•œë¯¼êµ­ í•µì‹¬ ì •ë¶€ì§€ì›/ê³µê³  ì‚¬ì´íŠ¸ ë¦¬ìŠ¤íŠ¸ (15ê³³) ---
TARGET_SITES_MAP = {
    # 1. ì¢…í•©/ì°½ì—…/ì¡°ë‹¬
    "k-startup.go.kr": "K-Startup",
    "bizinfo.go.kr": "ê¸°ì—…ë§ˆë‹¹",
    "g2b.go.kr": "ë‚˜ë¼ì¥í„°(ì…ì°°/ê³µê³ )",  # [ì‹ ê·œ] ì¡°ë‹¬ì²­
    "kvic.or.kr": "í•œêµ­ë²¤ì²˜íˆ¬ì(ëª¨íƒœí€ë“œ)", # [ê°•ì¡°] VC ì¶œìì‚¬ì—…

    # 2. R&D/ê¸°ìˆ /ì—°êµ¬
    "smtech.go.kr": "SMTech(ì¤‘ê¸°ë¶€R&D)",
    "nrf.re.kr": "í•œêµ­ì—°êµ¬ì¬ë‹¨(ê¸°ì´ˆì—°êµ¬)", # [ì‹ ê·œ] ì—°êµ¬ê³¼ì œ
    "iris.go.kr": "IRIS(ë²”ë¶€ì²˜R&D)",
    "nipa.kr": "NIPA(AI/SW)",
    "iitp.kr": "IITP(ICT)",
    "keit.re.kr": "KEIT(ì‚°ì—…ê¸°ìˆ )",

    # 3. ë¶„ì•¼ë³„ íŠ¹í™”
    "kocca.kr": "ì½˜í…ì¸ ì§„í¥ì›",
    "khidi.or.kr": "ë³´ê±´ì‚°ì—…ì§„í¥ì›",
    "nia.or.kr": "NIA(ë°ì´í„°/ì§€ëŠ¥)",
    "tp.or.kr": "í…Œí¬ë…¸íŒŒí¬(ì§€ì—­ê±°ì )",
    "venture.or.kr": "ë²¤ì²˜ê¸°ì—…í˜‘íšŒ"
}

def generate_search_queries(profile):
    """
    ì‚¬ì´íŠ¸ ì„±ê²©ì— ë”°ë¼ ê·¸ë£¹ì„ ë‚˜ëˆ„ì–´ ê²€ìƒ‰ íš¨ìœ¨ì„ ë†’ì…ë‹ˆë‹¤.
    """
    current_year = datetime.now().year
    queries = []
    
    # --- ê²€ìƒ‰ ê·¸ë£¹ ì •ì˜ (URL ê¸¸ì´ê°€ ë„ˆë¬´ ê¸¸ì–´ì§€ì§€ ì•Šê²Œ ë¶„ë¦¬) ---
    
    # Group A: ì‚¬ì—…í™”, ì°½ì—…ìê¸ˆ, ì¡°ë‹¬, íˆ¬ì (ëˆì´ ê¸‰í•œ ê³³)
    sites_biz = [
        "site:k-startup.go.kr", "site:bizinfo.go.kr", 
        "site:g2b.go.kr", "site:kvic.or.kr", "site:venture.or.kr"
    ]
    query_biz = "(" + " OR ".join(sites_biz) + ")"

    # Group B: R&D, ê¸°ìˆ ê°œë°œ, ì—°êµ¬ê³¼ì œ (ê¸°ìˆ  ì¤‘ì‹¬)
    sites_rnd = [
        "site:smtech.go.kr", "site:nrf.re.kr", "site:iris.go.kr",
        "site:nipa.kr", "site:iitp.kr", "site:keit.re.kr"
    ]
    query_rnd = "(" + " OR ".join(sites_rnd) + ")"
    
    # Group C: íŠ¹í™” ë¶„ì•¼ (ì½˜í…ì¸ , ë°”ì´ì˜¤ ë“± - ì‚°ì—…ë¶„ì•¼ì— ë”°ë¼ ì„ íƒì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•˜ë‚˜ ì—¬ê¸°ì„  í¬ê´„ ê²€ìƒ‰)
    sites_spec = [
        "site:kocca.kr", "site:khidi.or.kr", "site:nia.or.kr", "site:tp.or.kr"
    ]
    query_spec = "(" + " OR ".join(sites_spec) + ")"

    # --- ì¿¼ë¦¬ ìƒì„± ---
    for ind in profile.industry:
        clean_ind = ind.split('(')[0] # "ì¸ê³µì§€ëŠ¥"
        
        # 1. ì‚¬ì—…í™”/ìê¸ˆ ê·¸ë£¹ì—ì„œ ê²€ìƒ‰ (ë‚˜ë¼ì¥í„°, ë²¤ì²˜íˆ¬ì í¬í•¨)
        queries.append(f'{query_biz} "{clean_ind}" ì§€ì›ì‚¬ì—… ê³µê³  {current_year}')
        
        # 2. R&D ê·¸ë£¹ì—ì„œ ê²€ìƒ‰ (ì—°êµ¬ì¬ë‹¨ í¬í•¨)
        queries.append(f'{query_rnd} "{clean_ind}" ì—°êµ¬ê°œë°œ ê³¼ì œ ê³µê³  {current_year}')
        
        # 3. íŠ¹í™” ê·¸ë£¹ì—ì„œë„ í•œë²ˆ í›‘ê¸°
        queries.append(f'{query_spec} "{clean_ind}" ì§€ì›ì‚¬ì—… {current_year}')

    # ëª©ì ë³„ ì •ë°€ íƒ€ê²ŸíŒ…
    if "ì¡°ë‹¬" in profile.goal or "íŒë¡œ" in profile.goal:
        queries.append(f'site:g2b.go.kr "{clean_ind}" ì…ì°° ê³µê³  {current_year}')
    
    if "íˆ¬ì" in profile.goal:
        queries.append(f'site:kvic.or.kr ëª¨íƒœí€ë“œ ì¶œìì‚¬ì—… ê³µê³  {current_year}')

    # ì¿¼ë¦¬ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ëŠë ¤ì§€ë¯€ë¡œ ìƒìœ„ 5ê°œë¡œ ì œí•œ
    return queries[:5]

def extract_date(text):
    match = re.search(r'202\d[-.](0[1-9]|1[0-2])[-.](0[1-9]|[12]\d|3[01])', text)
    if match:
        return match.group(0)
    return None

def detect_agency(link):
    for domain, name in TARGET_SITES_MAP.items():
        if domain in link:
            return name
    return "ì •ë¶€ê³µê³ "

async def search_duckduckgo(query):
    results = []
    print(f"ğŸ•µï¸ [Full-Coverage] ê²€ìƒ‰ì–´: {query}")
    
    try:
        with DDGS() as ddgs:
            # ê²€ìƒ‰ ë²”ìœ„ í™•ì¥
            ddg_results = list(ddgs.text(query, region='kr-kr', timelimit='m', max_results=4))
            
        for r in ddg_results:
            link = r.get('href', '')
            title = r.get('title', '')
            body = r.get('body', '')
            
            agency = detect_agency(link)
            found_date = extract_date(body)
            
            results.append({
                "title": title.split(" - ")[0], 
                "agency": agency, 
                "date": datetime.now().strftime("%Y-%m-%d"),
                "deadline": found_date if found_date else "ê³µê³ ë¬¸ ì°¸ì¡°",
                "d_day": "D-??",
                "link": link,
                "match_score": 85 if agency != "ì •ë¶€ê³µê³ " else 70, 
                "summary": body
            })
            
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
    return results

async def get_notices(profile):
    queries = generate_search_queries(profile)
    all_results = []
    
    for q in queries:
        res = await search_duckduckgo(q)
        all_results.extend(res)
        
    unique_results = {v['link']: v for v in all_results}.values()
    final_list = list(unique_results)
    
    return final_list